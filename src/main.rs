#![feature(backtrace)]

extern crate image;

use std::fs::File;
use std::io::{Read, Write};
use std::iter::Iterator;
use std::path::Path;

use curl::easy::Easy;
use docopt::Docopt;
use flate2::read::GzDecoder;
use serde::Deserialize;
use url::Url;

use crate::error::Error;

use juice::layer::{LayerConfig, LayerType, Layer};
use juice::layers::{LinearConfig, NegativeLogLikelihoodConfig, SequentialConfig};

use juice::util::{native_backend, write_batch_sample};

use juice::solver::{Solver, SolverConfig, ConfusionMatrix};
use std::rc::Rc;

use byteorder::{BigEndian, ByteOrder, ReadBytesExt};
use std::iter::FromIterator;
use crate::dataIter::{DataIter, BatchDataIter};
use coaster::{SharedTensor, Backend, Native};
use std::sync::{Arc, RwLock};
use std::borrow::BorrowMut;

mod error;
mod dataIter;

const DATA_LINKS: [&str; 4] = [
    "http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz",
    "http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz",
    "http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz",
    "http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz",
];

const USAGE: &'static str = "
Juice MNIST Example

Usage:
juice_mnist download <directory>
juice_mnist train <batch> <hidden> [<file>] [--learning-rate=<rate>]
juice_mnist test <config> <batch>
juice_mnist (-h | --help)

Commands:
  download                            Downloads the datasets
  train <batch> <hidden> <file>       Trains the network and saves it based on the data in the \"data\" directory
  test <config> <batch>                      Tests the saved data based on the passed in config generated by --train.

Options:
  -h --help                 Show this screen.
  --learning-rate=<rate>    Learning rate that's used by the model.
";

#[derive(Debug, Deserialize)]
struct Args {
    cmd_download: bool,
    cmd_train: bool,
    cmd_test: bool,
    arg_directory: Option<String>,
    arg_config: Option<String>,
    arg_batch: Option<usize>,
    arg_hidden: Option<usize>,
    arg_file: Option<String>,
    flag_learning_rate: Option<f32>,
}

fn download_datasets(dir: Option<String>) -> Result<(), Error> {
    let directory = dir.ok_or("Please specify a directory when downloading datasets")?;

    let mut easy = Easy::new();

    for s in DATA_LINKS.iter() {
        let s = *s;
        let url = Url::parse(s)?;
        let filename: &str = url
            .path_segments()
            .ok_or("Could not get path segments")?
            .last()
            .ok_or("Could not get last path segment")?;

        let path = Path::new::<str>(directory.as_ref()).join(filename);
        let path = path.as_path();
        println!("Downloading {:?}", path.file_name().unwrap());
        {
            let mut file = File::create(path).expect("Failed to create a file to write to");

            easy.url(s)?;
            easy.write_function(move |data| {
                file.write_all(&data).unwrap();
                Ok(data.len())
            })?;
            easy.perform().unwrap();
        }

        {
            let mut gzippedBytes: Vec<u8> = vec![];
            let file = File::open(path)?;
            let mut decoder = GzDecoder::new(file);
            println!("Decoding file {:?}", path.file_name().unwrap());
            decoder.read_to_end(&mut gzippedBytes);

            // Write the decoded file
            let path = Path::new::<str>(directory.as_ref()).join(filename.replace(".gz", ""));
            let mut unzipped_file = File::create(path)?;
            unzipped_file.write_all(gzippedBytes.as_slice())?;
        }
    }
    Ok(())
}

fn readu32(file: &File) -> Result<u32, Error> {
    let mut values = [0u8; 4];
    let mut taker = file.take(4);
    taker.read(&mut values)?;

    Ok(BigEndian::read_u32(&values))
}

fn getModelCfg(batch_size: usize, input_dimensions: (usize, usize), hidden_layer_size: usize) -> LayerConfig {
    // let linear_1 = LayerConfig::new("linear1", LinearConfig { output_size: hidden_layer_size });
    let linear_2 = LayerConfig::new("linear2", LinearConfig { output_size: 10 });

    // let first_activation = LayerConfig::new("sigmoid", LayerType::TanH);
    let last_activation = LayerConfig::new("softmax", LayerType::LogSoftmax);

    let mut total_config = SequentialConfig::default();
    total_config.add_input(
        "data",
        &vec![batch_size, input_dimensions.0, input_dimensions.1],
    );
    // total_config.add_layer(linear_1);
    // total_config.add_layer(first_activation);
    total_config.add_layer(linear_2);
    total_config.add_layer(last_activation);

    LayerConfig::new("model", LayerType::Sequential(total_config))
}

fn getSolverCfg(batch_size: usize, output_size: usize) -> LayerConfig {
    let nll_config = LayerConfig::new(
        "neg. log likelihood",
        NegativeLogLikelihoodConfig {
            num_classes: output_size,
        },
    );

    let mut config = SequentialConfig::default();
    config.add_input("network_output", &[batch_size, output_size]);
    config.add_input("label", &[batch_size, 1]);
    config.add_layer(nll_config);

    LayerConfig::new("solver", LayerType::Sequential(config))
}

fn train_dataset(batch_size: Option<usize>, hidden_layer_size: Option<usize>, file: Option<String>, learning_rate: Option<f32>) -> Result<(), Error> {
    let train_label_path = Path::new("data/train-labels-idx1-ubyte");
    let train_image_path = Path::new("data/train-images-idx3-ubyte");

    let mut trainLabelFile = File::open(train_label_path)?;
    let mut trainImageFile = File::open(train_image_path)?;

    // These magic numbers verify that you are reading bits the right way
    assert_eq!(readu32(&trainLabelFile)?, 2049);
    assert_eq!(readu32(&trainImageFile)?, 2051);

    let num_of_records = readu32(&trainLabelFile)?;
    assert_eq!(num_of_records, readu32(&trainImageFile)?);

    let rows = readu32(&trainImageFile)? as usize;
    let cols = readu32(&trainImageFile)? as usize;

    println!("Image dimensions are: ({}, {})", rows, cols);

    // Put this in a command param
    let batch_size = batch_size.unwrap_or(10);
    let output_size = 10usize;

    let network_cfg = getModelCfg(batch_size, (rows, cols), hidden_layer_size.unwrap_or(500));
    let object_cfg = getSolverCfg(batch_size, output_size);

    let mut solver_cfg = SolverConfig::default();
    solver_cfg.network = network_cfg;
    solver_cfg.objective = object_cfg;
    solver_cfg.base_lr = learning_rate.unwrap_or(0.1);

    let native_backend = Rc::new(native_backend());
    let mut solver = Solver::from_config(native_backend.clone(), native_backend.clone(), &solver_cfg);

    let mut data_iter: DataIter = DataIter::new(&mut trainLabelFile, &mut trainImageFile, rows, cols);
    let mut batch_iter: BatchDataIter = BatchDataIter { dataIter: data_iter, batch_size };

    let mut label_tensor: SharedTensor<f32> = SharedTensor::new(&[batch_size, 1]);
	let mut inp_tensor: SharedTensor<f32> = SharedTensor::new(&[batch_size, rows*cols]);

    let mut label_lock = Arc::new(RwLock::new(label_tensor));
    let mut inp_lock = Arc::new(RwLock::new(inp_tensor));

    let mut confusion = ConfusionMatrix::new(output_size);

	for batch in batch_iter {
       for i in 0..batch_size {
           let mut labels = label_lock.write()?;
           let mut inputs = inp_lock.write()?;
           write_batch_sample(&mut labels, &[batch.get(i).unwrap().0], i);
           write_batch_sample(&mut inputs, batch.get(i).unwrap().1.as_slice(), i);
       }

        let inferred = solver.train_minibatch(inp_lock.clone(), label_lock.clone());
		let mut inferred = inferred.write()?;
        let predictions = confusion.get_predictions(&mut inferred);
        let labels = Vec::from_iter(batch.iter().map(|(u, v)| {
            *u as usize
        }));

        println!("  Predictions were: {:?}", &predictions);
		println!("Actual Labels were: {:?}", &labels);

        confusion.add_samples(&predictions, &labels);

        println!("Accuracy: {}", confusion.accuracy());
    }

    if let Some(f) = file {
        println!("Writing network to {}", f);
        solver.mut_network().save(f);
    }

    Ok(())
}

fn test_dataset(path: Option<String>, batch_size: Option<usize>) -> Result<(), Error> {
    let test_label_path = Path::new("data/t10k-labels-idx1-ubyte");
    let test_image_path = Path::new("data/t10k-images-idx3-ubyte");

    let backend = Rc::new(native_backend());
    let mut network: Layer<Backend<Native>> =  Layer::<Backend<Native>>::load(backend, path.unwrap())?;

    let batch_size = batch_size.unwrap_or(10);

    let mut confusion_matrix = ConfusionMatrix::new(10);

    let mut test_label_file = File::open(test_label_path)?;
    let mut test_image_file = File::open(test_image_path)?;

    // These magic numbers verify that you are reading bits the right way
    assert_eq!(readu32(&test_label_file)?, 2049);
    assert_eq!(readu32(&test_image_file)?, 2051);

    let num_of_records = readu32(&test_label_file)?;
    assert_eq!(num_of_records, readu32(&test_image_file)?);

    let rows = readu32(&test_image_file)? as usize;
    let cols = readu32(&test_image_file)? as usize;

    println!("Image dimensions are: ({}, {})", rows, cols);

    let data_iter = DataIter {
        labelFile: &mut test_label_file,
        imageFile: &mut test_image_file,
        rows,
        cols
    };

    let batch_iter = BatchDataIter {
        dataIter: data_iter,
        batch_size,
    };

	let mut label_tensor = SharedTensor::<f32>::new(&[batch_size, 1]);
    let mut image_tensor = SharedTensor::<f32>::new(&[batch_size, rows*cols]);

    let mut label_lock = Arc::new(RwLock::new(label_tensor));
    let mut image_lock = Arc::new(RwLock::new(image_tensor));

    for batch in batch_iter {
	    let mut labels = vec![];
        for (i, (label, data)) in batch.iter().enumerate() {
            labels.push(*label as usize);
            let mut labels = label_lock.write()?;
	        let mut images = image_lock.write()?;

            write_batch_sample(&mut labels, &[*label as usize], i);
            write_batch_sample(&mut images, data.as_slice(), i);
        }
        let results_vec = network.forward(&[image_lock.clone()]);

        let mut results = results_vec.get(0).unwrap().write()?;
        let predictions = confusion_matrix.get_predictions(&mut results);

        confusion_matrix.add_samples(predictions.as_slice(), labels.as_slice());
    }

    println!("Accuracy is {}", confusion_matrix.accuracy());

    Ok(())
}

fn main() -> Result<(), Error> {
    let args: Args = Docopt::new(USAGE)
        .and_then(|d| d.deserialize())
        .unwrap_or_else(|e| e.exit());

    println!("{:?}", args);

    if args.cmd_download {
        download_datasets(args.arg_directory)?;
    } else if args.cmd_train {
        train_dataset(args.arg_batch, args.arg_hidden, args.arg_file, args.flag_learning_rate)?;
    } else if args.cmd_test {
        test_dataset(args.arg_config, args.arg_batch)?;
    }

    Ok(())
}
